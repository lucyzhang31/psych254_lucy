comt7.model1 = '
Schizo ~ EarlyOn + GenxEnv + Psysym
Psysym ~ EarlyOn + Conduct + Schizo
Conduct ~ EarlyOn
Chpsyq ~ COMT
'
comt7.fit1 = sem(comt7.model1, fixed.x = F, sample.cov = comt7.cov, sample.nobs = 803) #fixed.x = F causes it to automatically estimate covariances among exogenous (aka independent) variables. Otherwise, you would have to specify covariances manually. These must be explicitly removed if you don't want them.
comt7.fit1 = sem(comt7.model1, fixed.x = False, sample.cov = comt7.cov, sample.nobs = 803) #fixed.x = F causes it to automatically estimate covariances among exogenous (aka independent) variables. Otherwise, you would have to specify covariances manually. These must be explicitly removed if you don't want them.
comt7.fit1 = sem(comt7.model1, fixed.x = FALSE, sample.cov = comt7.cov, sample.nobs = 803) #fixed.x = F causes it to automatically estimate covariances among exogenous (aka independent) variables. Otherwise, you would have to specify covariances manually. These must be explicitly removed if you don't want them.
summary(comt7.fit1)
comt7.model2 = '
Schizo ~ EarlyOn + GenxEnv + Psysym
Psysym ~ EarlyOn + Conduct + Schizo
Conduct ~ EarlyOn
Chpsyq ~ COMT
GenxEnv ~~ 0*COMT
EarlyOn ~~ GenxEnv + COMT
'
comt7.fit2 = sem(comt7.model2, fixed.x = FALSE, sample.cov = comt7.cov, sample.nobs = 803) #fixed.x = F causes it to automatically estimate covariances among exogenous (aka independent) variables. Otherwise, you would have to specify covariances manually. These must be explicitly removed if you don't want them.
summary(comt7.fit2)
anova(comt7.fit1, comt7.fit2) #it looks like deleting that covariance arbitrarily made the model worse D:
modificationIndices(comt7.fit1) #The "mi" column gives a rough approximation of how the model would improve if new parameters were added. EPC = expected parameter change
comt7.model3 = '
Schizo ~ EarlyOn + GenxEnv + Psysym + Chpsyq
Psysym ~ EarlyOn + Conduct + Schizo
Conduct ~ EarlyOn
Chpsyq ~ COMT
GenxEnv ~ Chpsyq
EarlyOn ~~ GenxEnv + COMT
GenxEnv ~~ COMT
'
comt7.fit3 = sem(comt7.model3, fixed.x = F, sample.cov = comt7.cov, sample.nobs = 803)
comt7.fit3 = sem(comt7.model3, fixed.x = FALSE, sample.cov = comt7.cov, sample.nobs = 803)
anova(comt7.fit1, comt7.fit3) #our new model has a lower chisq value!
summary(comt7.fit3)
modificationindices(comt7.fit3)
comt7.model4 = '
Schizo ~ EarlyOn + GenxEnv + Psysym + Chpsyq
Psysym ~ EarlyOn + Conduct + Schizo
Conduct ~ EarlyOn + Chpsyq
Chpsyq ~ COMT
GenxEnv ~ Chpsyq
EarlyOn ~~ GenxEnv + COMT
GenxEnv ~~ COMT
'
comt7.fit4 = sem(comt7.model4, fixed.x = F, sample.cov = comt7.cov, sample.nobs = 803)
anova(comt7.fit1, comt7.fit3, comt7.fit4) #Wow, it's so much better now!
comt7.fit4 # non-significant p value!!!!!!
comt7.model4 = '
Schizo ~ EarlyOn + GenxEnv + Psysym + Chpsyq
Psysym ~ EarlyOn + Conduct + Schizo
Conduct ~ EarlyOn + Chpsyq
Chpsyq ~ COMT
GenxEnv ~ Chpsyq
EarlyOn ~~ GenxEnv + COMT
GenxEnv ~~ COMT
'
comt7.fit4 = sem(comt7.model4, fixed.x = FALSE, sample.cov = comt7.cov, sample.nobs = 803)
anova(comt7.fit1, comt7.fit3, comt7.fit4) #Wow, it's so much better now!
comt7.fit4
comt7.fit4 # non-significant p value!!!!!!
low.dom = '
1
.415 1
.460 .351 1
-.321 -.374 -.310 1
-.239 -.221 -.133 .626 1
-.185 -.164 -.272 .533 .345 1
.349 .307 .496 -.180 -.081 -.067 1
.308 .302 .562 -.222 -.156 -.118 .573 1
.038 -.115 -.048 .296 .167 .320 .008 -.036 1
-.072 -.160 -.124 .317 .167 .248 -.152 -.175 .414 1
'
labels1 = c("FSOR", "FSIR", "FSSR", "MSOR", "MSIR", "MSSR", "FTFR", "FTSR", "MTSR", "MTFR")
dom.cov = getCov(low.dom, names = labels1)
dyad.model1 = '
# Latent variable definitions for trait, FTZ & MTZ, and situation, FSZ & MSZ
FTZ =~ FTSR + FTFR
MTZ =~ MTSR + MTFR
FSZ =~ FSSR + FSIR + FSOR
MSZ =~ MSSR + MSIR + MSOR
# regressions
FSZ ~ B*FTZ + C*MSZ
MSZ ~ A*MTZ + D*FSZ
# variances and covariances
# Residual correls among M ratings, MTSR, MSSR, FSIR
MTSR + MSSR ~~ FSIR
MSSR ~~ MTSR
# Residual correls among F ratings, FTSR, FSSR, MSIR
FTSR + FSSR ~~ MSIR
FSSR ~~ FTSR
# Residual correls among Observer situational ratings, MSOR, FSOR
MSOR ~~ FSOR
'
dyad.fit1 = sem(dyad.model1, fixed.x = F, sample.cov = dom.cov, sample.nobs = 112)
dyad.fit1 = sem(dyad.model1, fixed.x = FALSE, sample.cov = dom.cov, sample.nobs = 112)
summary(dyad.fit1) #good p value, but can we make a simpler model that works?
dyad.model2 = '
# Latent variable definitions for trait, FTZ & MTZ, and situation, FSZ & MSZ
FTZ =~ FTSR + FTFR
MTZ =~ MTSR + MTFR
FSZ =~ FSSR + FSIR + FSOR
MSZ =~ MSSR + MSIR + MSOR
# regressions
FSZ ~ B*FTZ + C*MSZ
MSZ ~ A*MTZ + D*FSZ
# Residual correls among M ratings, MTSR, MSSR
MSSR ~~ MTSR
# Residual correls among F ratings, FTSR, FSSR
FSSR ~~ FTSR
'
dyad.fit2 = sem(dyad.model2, fixed.x = T, sample.cov = dom.cov, sample.nobs = 112) #notice how i set fixed.x = T here so it wouldn't automatically add terms I didn't want
summary(dyad.fit2) # Wow, even better !
anova(dyad.fit1,dyad.fit2)
summary(dyad.fit2) # Wow, even better !
dyad.model3 = '
# Latent variable definitions for trait, FTZ & MTZ, and situation, FSZ & MSZ
FTZ =~ FTSR + FTFR
MTZ =~ MTSR + MTFR
FSZ =~ FSSR + FSIR + FSOR
MSZ =~ MSSR + MSIR + MSOR
# regressions
FSZ ~ B*FTZ + C*MSZ
MSZ ~ A*MTZ + C*FSZ
# Residual correls among M ratings, MTSR, MSSR
MSSR ~~ MTSR
# Residual correls among F ratings, FTSR, FSSR
FSSR ~~ FTSR
'
dyad.fit3 = sem(dyad.model3, fixed.x = T, sample.cov = dom.cov, sample.nobs = 112) #notice how i set fixed.x = T here so it wouldn't automatically add terms I didn't want
summary(dyad.fit3)
anova(dyad.fit1,dyad.fit2,dyad.fit3) #looks like constraining it made the model better! So they probably aren't actually different
#could also test it this way:
dyad.fit3a = sem(dyad.model2, fixed.x = F, sample.cov = dom.cov, sample.nobs = 112, constraints = 'C - D == 0', start = dyad.fit2) #using our model2 design, but constraining C-D to be 0
print(summary(dyad.fit3a)) #same result as before
dyad.fit3a = sem(dyad.model2, fixed.x = FALSE, sample.cov = dom.cov, sample.nobs = 112, constraints = 'C - D == 0', start = dyad.fit2) #using our model2 design, but constraining C-D to be 0
print(summary(dyad.fit3a)) #same result as before
remove.packages("plyr")
library("ggplot2", lib.loc="/Library/Frameworks/R.framework/Versions/2.15/Resources/library")
g = (ggplot(data=d2, aes(x=stress, y=depress, color=socsup))
+geom_point()
+facet_wrap(~ subid + socsup, ncol=5, scales = 'fixed')
+stat_smooth(method='lm')
)
library('ggplot2')
library("psych", lib.loc="/Library/Frameworks/R.framework/Versions/2.15/Resources/library")
glm
power.t.test(delta=.25, sd=2, sig.level=.05, power=NULL, alternative = 'one.sided', type = 'one.sample')
power.t.test(n=null, delta=0.2, sd=1, sig.level=.05,power=.2, type="one.sample", alternative="two.sided")  #This creates a new variable in a dataset using a part of the power analyses
power.t.test(delta=0.2, sd=1, sig.level=.05,power=.2, type="one.sample", alternative="two.sided")
power.t.test(delta=0.4, sd=1, sig.level=.05,power=.2, type="one.sample", alternative="two.sided")
power.t.test(delta=0.1, sd=1, sig.level=.05,power=.2, type="one.sample", alternative="two.sided")
power.t.test(delta=0.1, sd=2, sig.level=.05,power=.2, type="one.sample", alternative="two.sided")
power.t.test(delta=0.3, sd=2, sig.level=.05,power=.2, type="one.sample", alternative="two.sided")
power.t.test(delta=0.2, sd=2, sig.level=.05,power=.2, type="one.sample", alternative="two.sided")
power.t.test(delta=0.1, sd=2, sig.level=.05,power=.2, type="one.sample", alternative="two.sided")
power.t.test(delta=0.1, sd=1, sig.level=.05,power=.2, type="one.sample", alternative="two.sided")
install.packages("ez")
install.packages("lsmeans")
install.packages("nlme")
install.packages(c("AER", "boot", "car", "class", "cluster", "colorspace", "dichromat", "digest", "foreign", "ggm", "gsl", "gtable", "igraph", "KernSmooth", "labeling", "lattice", "lavaan", "lmtest", "lpSolve", "MASS", "maxLik", "MBESS", "mediation", "mgcv", "mlogit", "mnormt", "multcomp", "mvtnorm", "nnet", "ordinal", "proto", "psych", "quadprog", "reshape2", "rpart", "sandwich", "scatterplot3d", "spatial", "statmod", "stringr", "strucchange", "zoo"))
install.packages(c("AER", "boot", "car", "class", "cluster",
library(ggplot2)
library(reshape2)
library(bootstrap)
library(lme4)
library(stringr)
library(lubridate)
library(plyr) # first load plyr then dplyr from https://github.com/hadley/dplyr
library(dplyr)
library(tidyr)
d <- read.csv("/Users/lucyzhang/documents/254/psych254_materials/data/janiszewski_rep_exercise.csv")
View(d)
d <- read.csv("/Users/lucyzhang/documents/254/psych254_materials/data/janiszewski_rep_cleaned.csv")
View(d)
d.tidy<-select(d, Input.price1, Input.price2, Input.price3, Input.condition, Answer.dog_cost, Answer.plasma_cost, Answer.sushi_cost)
```
View(d.tidy)
```{r rename}
d.tidy<-rename(d.tidy, sushi=Answer.sushi_cost)
d.tidy<-rename(d.tidy, condition=Input.condition)
d.tidy<-rename(d.tidy, price1=Input.price1); d.tidy<-rename(d.tidy, price2=Input.price2); d.tidy<-rename(d.tidy, price3=Input.price3)
d.tidy<-rename(d.tidy, dog=Answer.dog_cost); d.tidy<-rename(d.tidy, plasma=Answer.plasma_cost)
d.tidy2<-select(d.tidy, condition, dog, plasma, sushi)
```
View(d.tidy)
View(d.tidy2)
d.tidy3<-gather(d.tidy2, item, answerprice, -condition)
View(d.tidy3)
View(d.tidy3)
d.wide <- sperad(d.tidy3, items)
d.wide <- spread(d.tidy3, items)
d.wide <- spread(d.tidy3, item)
d.wide <- spread(d.tidy3, item, answerprice)
d.tidy<-select(d, WorkerId, Input.price1, Input.price2, Input.price3, Input.condition, Answer.dog_cost, Answer.plasma_cost, Answer.sushi_cost)
View(d.tidy)
View(d.tidy)
d.tidy2<-select(d.tidy, WorkerId, condition, dog, plasma, sushi)
View(d.tidy2)
View(d.tidy2)
View(d.tidy3)
d.tidy2<-select(d.tidy, WorkerId, condition, dog, plasma, sushi)
d.tidy<-rename(d.tidy, sushi=Answer.sushi_cost)
d.tidy<-rename(d.tidy, condition=Input.condition)
d.tidy<-rename(d.tidy, price1=Input.price1); d.tidy<-rename(d.tidy, price2=Input.price2); d.tidy<-rename(d.tidy, price3=Input.price3)
d.tidy<-rename(d.tidy, dog=Answer.dog_cost); d.tidy<-rename(d.tidy, plasma=Answer.plasma_cost)
d.tidy2<-select(d.tidy, WorkerId, condition, dog, plasma, sushi)
```
View(d.tidy2)
View(d.tidy3)
d.tidy3<-gather(d.tidy2, WorkerId, item, answerprice, -condition)
View(d.tidy3)
View(d.tidy3)
d.tidy3<-gather(d.tidy2, item, answerprice, -condition, -WorkerId)
View(d.tidy3)
View(d.tidy3)
View(d.tidy3)
d.wide <- spread(d.tidy3, WorkerId, answerprice)
View(d.wide)
d.wide <- spread(d.tidy3, answerprice, WorkerId)
View(d.wide)
View(d.wide)
d.wide <- spread(d.tidy3, item, answerprice)
View(d.wide)
View(d.wide)
d.raw <- read.csv("/Users/lucyzhang/documents/254/psych254_materials/data/janiszewski_rep_cleaned.csv")
d.unique.subs<-distinct(d.raw, WorkerId)
View(d.unique.subs)
View(d.unique.subs)
d.raw <- read.csv("/Users/lucyzhang/documents/254/psych254_materials/data/janiszewski_rep_exercise.csv")
View(d.tidy2)
summarise(d.tidy2, plasma=mean(plasma))
summarise(d.tidy2, sushi=mean(sushi))
summarise(d.tidy2, sushi=mean(sushi, na.rm=True))
summarise(d.tidy2, sushi=mean(sushi), na.rm=True)
?summarise
d.tidy3 %>%
group_by(item, na.rm=TRUE) %>%
summarise(price=mean(answerprice))
d.tidy3 %>%
group_by(item, na.rm=TRUE) %>%
summarise(price=mean(answerprice, na.rm=TRUE))
summarise(d.tidy2, sushi=mean(sushi, na.rm=TRUE))
pcts <- d.tidy %>%
mutate(pct_change = abs((anchor-cost)/anchor)) %>%
group_by(condition) %>%
summarize(pct_change=mean(pct_change, na.rm=TRUE))
d.tidy <- d %>%
select(WorkerId, Input.condition,
starts_with("Answer"),
starts_with("Input")) %>%
rename(workerid = WorkerId,
condition = Input.condition,
plasma_anchor = Input.price1,
dog_anchor = Input.price2,
sushi_anchor = Input.price3,
dog_cost = Answer.dog_cost,
plasma_cost = Answer.plasma_cost,
sushi_cost = Answer.sushi_cost) %>%
gather(name, cost,
dog_anchor, plasma_anchor, sushi_anchor,
dog_cost, plasma_cost, sushi_cost) %>%
separate(name, c("item", "type"), sep = "_") %>%
spread(type, cost)
pcts <- d.tidy %>%
mutate(pct_change = abs((anchor-cost)/anchor)) %>%
group_by(condition) %>%
summarize(pct_change=mean(pct_change, na.rm=TRUE))
View(pcts)
pcts2 <- d.tidy %>%
mutate(pct_change = abs((anchor-cost)/anchor)) %>%
group_by(item) %>%
summarize(pct_change=mean(pct_change, na.rm=TRUE))
View(pcts2)
View(pcts)
?scale
z-scores <- d %>%
group_by(item, na.rm=TRUE) %>%
summarize(mean(pct_change, na.rm=TRUE)) %>%
summarize(sd(pct_change, na.rm=TRUE))
View(pcts2)
View(pcts2)
View(pcts)
?scalle
?scale
z-scores <- pcts %>%
group_by(item, na.rm=TRUE) %>%
group_by(condition, add=TRUE)
View(pcts2)
z-scores <- d %>%
group_by(item, na.rm=TRUE) %>%
group_by(condition, add=TRUE) %>%
n
z-scores <- d %>%
group_by(item, na.rm=TRUE) %>%
group_by(condition, add=TRUE) %>%
summarize(z=mean(pct_change, na.rm=TRUE))
View(d)
View(d.raw)
View(d.unique.subs)
View(d.wide)
View(pcts)
View(pcts2)
d.tidy <- d %>%
select(WorkerId, Input.condition,
starts_with("Answer"),
starts_with("Input")) %>%
rename(workerid = WorkerId,
condition = Input.condition,
plasma_anchor = Input.price1,
dog_anchor = Input.price2,
sushi_anchor = Input.price3,
dog_cost = Answer.dog_cost,
plasma_cost = Answer.plasma_cost,
sushi_cost = Answer.sushi_cost) %>%
gather(name, cost,
dog_anchor, plasma_anchor, sushi_anchor,
dog_cost, plasma_cost, sushi_cost) %>%
separate(name, c("item", "type"), sep = "_") %>%
spread(type, cost)
View(d.tidy)
?mutate
View(pcts)
chisq(pct_change)
?chisq
chisq.test(pcts, pct_change)
?chisq.test
chisq.test(pcts, x=condition, y=pct_change)
chisq.test(as.table(pcts$pct_change))
z-scores <- d.tidy %>%
group_by(item, na.rm=TRUE) %>%
mutate(z=scale(cost)[,1]) %>%
group_by(condition, add=TRUE) %>%
summarize(z=mean(z, na.rm=TRUE))
z.scores <- d.tidy %>%
group_by(item) %>%
mutate(z=scale(cost)[,1]) %>%
group_by(condition, add=TRUE) %>%
summarize(z=mean(z, na.rm=TRUE))
View(z.scores)
View(pcts2)
View(pcts2)
?scale
qplot(item, z, fill=condition,
position="dodge",
stat="identity", geom="bar",
data=z.scores)
library(ggplot2)
library(reshape2)
library(bootstrap)
library(lme4)
library(stringr)
library(lubridate)
library(plyr) # first load plyr then dplyr from https://github.com/hadley/dplyr
library(dplyr)
library(tidyr)
Part 1: Data cleaning
---------------------
install.packages("ggplot2")
library(ggplot2)
```
head(diamonds)
qplot(diamonds$carat, diamonds$price)
diamonds %>%
qplot(carat, price)
library(reshape2)
library(bootstrap)
library(lme4)
library(stringr)
library(lubridate)
library(plyr) # first load plyr then dplyr from https://github.com/hadley/dplyr
library(dplyr)
library(tidyr)
diamonds %>%
qplot(carat, price)
diamonds %>%
qplot(carat, price)
diamonds %>%
qplot(carat, price) %>%
m
diamonds %>%
qplot(carat, price)
```
head(diamonds)
diamonds %>%
qplot(carat, price)
qplot(diamonds$clarity, diamonds$price)
qplot(diamonds$cut, diamonds$price)
qplot(diamonds$color, diamonds$price)
qplot(diamonds$carat, diamonds$price)
d<-diamonds
View(d)
View(d)
d<-diamonds
d %>%
qplot(carat, price)
as.numeric(d$carat)
d %>%
qplot(carat, price)
library(ggplot2)
library(reshape2)
library(bootstrap)
library(lme4)
library(stringr)
library(lubridate)
library(plyr) # first load plyr then dplyr from https://github.com/hadley/dplyr
library(dplyr)
library(tidyr)
setwd("~/psych254_lucy/data")
d<-read.csv("sklar_expt6_subinfo_corrected.csv")
da<-read.csv("sklar_expt6a_corrected.csv")
db<-read.csv("sklar_expt6b_corrected.csv")
install.packages("stringer")
View(da)
View(da)
d.tidy<-gather(da, RT, -prime, -prime.result, -target, -congruent, -operand, -distance, -counterbalance)
?gather
d.tidy<-gather(da, X1:X21, -prime, -prime.result, -target, -congruent, -operand, -distance, -counterbalance)
d.tidy<-gather(da, X1:X21, na.rm=TRUE)
da %>% da.tidy<-gather(X1:X21, na.rm=TRUE)
da %>% da.tidy<-gather(X1:X21, na.rm=TRUE)
da.tidy<-gather(X1:X21, na.rm=TRUE)
da.tidy<-gather(X1:X21)
da.tidy<-gather(X1:X21, -prime)
da.tidy<-gather(prime, ID, X1:X21)
da %>% da.tidy<-gather(prime, ID, X1:X21)
da %>% da.tidy<-gather(ID, X1:X21)
da %>% da.tidy<-gather(ID, X1:X2)
da %>% da.tidy<-gather(ID, reaction, X1:X2)
da %>% da.tidy<-gather(ID, RT, X1:X2)
da %>% da.tidy<-gather(ID, RT, X1:X21)
View(da)
View(db)
db %>% db.tidy<-gather(ID, RT, X1:X21)
db %>% db.tidy<-gather(ID, RT, X22:X42)
db.tidy<-db %>% gather(key, RT, X22:X42)
View(db.tidy)
View(db.tidy)
da.tidy<-da %>% gather(key, RT, X1:X21)
View(da.tidy)
?stringer
install.packages("stringr")
install.packages("stringr")
data<-merge(db.tidy, da.tidy)
View(data)
data<-rbind(db.tidy, da.tidy)
View(data)
View(data)
View(data)
View(data)
da.tidy<-da %>% gather(ID, RT, X1:X21)
db.tidy<-db %>% gather(ID, RT, X22:X42)
library(ggplot2)
library(reshape2)
library(bootstrap)
library(lme4)
library(stringr)
library(lubridate)
library(plyr) # first load plyr then dplyr from https://github.com/hadley/dplyr
library(dplyr)
library(tidyr)
da.tidy<-da %>% gather(ID, RT, X1:X21)
db.tidy<-db %>% gather(ID, RT, X22:X42)
?join
data<-full_join(db.tidy, da.tidy)
View(data)
View(data)
p <- ggplot(data, aes(x=prime.result, y=RT))
ggplot(data, aes(x=prime.result, y=RT))
p<- ggplot(data, aes(x=prime.result, y=RT))
p + geom_point(aes(colour = distance))
p<- ggplot(data, aes(x=congruent, y=RT))
p + geom_point(aes(colour = counterbalance))
p<- ggplot(data, aes(x=distance, y=RT))
p + geom_point(aes(colour = counterbalance))
?qplot
p<- ggplot(data, aes(x=distance, y=RT))
p + geom_point(aes(colour = prime.result))
p<- ggplot(data, aes(x=primeresult, y=RT))
p + geom_point(aes(colour = prime.result))
p<- ggplot(data, aes(x=primeresult, y=RT))
p + geom_point(aes(colour = prime))
p<- ggplot(data, aes(x=prime.result, y=RT))
p + geom_point(aes(colour = prime))
p<- ggplot(data, aes(x=prime, y=RT))
p + geom_point(aes(colour = prime.result))
p<- ggplot(data, aes(x=prime, y=RT))
p + geom_point(aes(colour = ID))
p<- ggplot(data, aes(x=prime, y=RT))
p + geom_point(aes(colour = distance))
p<- ggplot(data, aes(x=prime.result, y=RT))
p + geom_point(aes(colour = distance))
p<- ggplot(data, aes(x=distance, y=RT))
p + geom_point(aes(colour = target))
p<- ggplot(data, aes(x=congruent, y=RT))
p + geom_point(aes(colour = distance))
qplot(data$congruent, data$RT)
plot(data$congruent,data$RT,xlab="Congruent Prime",ylab="Reaction time") # plot with Prime congruence on x-axis and RT (0 or 1) on y-axis
g=glm(data$RT~data$congruent,family=binomial,dat) # run a logistic regression model (in this case, generalized linear model with logit link). see ?glm
curve(predict(g,data.frame(data$congruent=x),type="resp"),add=TRUE) # draws a curve based on prediction from logistic regression model
points(data$congruent,fitted(g),pch=20) # optional: you could skip this draws an invisible set of points of body size survival based on a 'fit' to glm model. pch= changes type of dots.
```
plot(data$congruent,data$RT,xlab="Congruent Prime",ylab="Reaction time") # plot with Prime congruence on x-axis and RT (0 or 1) on y-axis
g=glm(data$RT~data$congruent,family=binomial,dat) # run a logistic regression model (in this case, generalized linear model with logit link). see ?glm
curve(predict(g,data.frame(data$congruent=x),type="resp"),add=TRUE) # draws a curve based on prediction from logistic regression model
p<- ggplot(data, aes(x=congruent, y=RT))
p + geom_point(aes(colour = distance))
p<- ggplot(data, aes(x=distance, y=RT))
p + geom_point(aes(colour = congruent))
hist(data$RT)
p + geom_point(aes(colour = distance))
?join
